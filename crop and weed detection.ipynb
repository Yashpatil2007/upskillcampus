{
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ravirajsinh45_crop_and_weed_detection_data_with_bounding_boxes_path = kagglehub.dataset_download('ravirajsinh45/crop-and-weed-detection-data-with-bounding-boxes')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "EFNQEWvLETqS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "Greetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing."
      ],
      "metadata": {
        "id": "KOf2GwG7ETqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Analysis\n",
        "To begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)"
      ],
      "metadata": {
        "id": "1lD16VjHETqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "id": "ZPPw-uwbETqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is 0 csv file in the current version of the dataset:\n"
      ],
      "metadata": {
        "id": "DlIIqCBVETqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "id": "ARjLCw6hETqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code."
      ],
      "metadata": {
        "id": "V4jjSPeGETqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "_kg_hide-input": true,
        "id": "s_MpEsq4ETqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    filename = df.dataframeName\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "_kg_hide-input": true,
        "id": "ftJxPDJVETqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter and density plots\n",
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "_kg_hide-input": true,
        "id": "7XRlKqKmETqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4625d63"
      },
      "source": [
        "import os\n",
        "\n",
        "# The path to the downloaded dataset is already available from the initial import.\n",
        "data_path = ravirajsinh45_crop_and_weed_detection_data_with_bounding_boxes_path\n",
        "\n",
        "print(f\"Contents of the downloaded dataset directory ({data_path}):\")\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0592766"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "classes_file_path = os.path.join(data_path, 'classes.txt')\n",
        "\n",
        "if os.path.exists(classes_file_path):\n",
        "    with open(classes_file_path, 'r') as f:\n",
        "        print(f\"Contents of {classes_file_path}:\")\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(f\"File not found: {classes_file_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ca2999"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define a list to store parsed annotation data\n",
        "annotations_data = []\n",
        "\n",
        "# Path to the data directory, assuming annotations are in 'agri_data/data'\n",
        "data_dir = os.path.join(data_path, 'agri_data', 'data')\n",
        "\n",
        "print(f\"Searching for annotation files in: {data_dir}\")\n",
        "\n",
        "# Iterate through files in the data directory\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith('.txt') and filename != 'classes.txt': # Exclude classes.txt and process only other .txt files\n",
        "        file_path = os.path.join(data_dir, filename)\n",
        "        image_filename = filename.replace('.txt', '.jpeg') # Assuming corresponding image is .jpeg\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split() # Assuming space-separated values\n",
        "                if len(parts) == 5: # Expecting class_id, x_center, y_center, width, height\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center, width, height = map(float, parts[1:])\n",
        "                    annotations_data.append({\n",
        "                        'image_name': image_filename,\n",
        "                        'class_id': class_id,\n",
        "                        'x_center': x_center,\n",
        "                        'y_center': y_center,\n",
        "                        'width': width,\n",
        "                        'height': height\n",
        "                    })\n",
        "\n",
        "# Create a pandas DataFrame from the collected data\n",
        "annotations_df = pd.DataFrame(annotations_data)\n",
        "\n",
        "print(f\"Successfully loaded {len(annotations_df)} annotations into a DataFrame.\")\n",
        "print(\"First 5 rows of the annotations DataFrame:\")\n",
        "print(annotations_df.head())\n",
        "\n",
        "# Display basic info about the DataFrame\n",
        "print(\"\\nDataFrame Info:\")\n",
        "annotations_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d7b3537"
      },
      "source": [
        "# Task\n",
        "Perform an exploratory data analysis of the bounding box annotations by:\n",
        "*   Analyzing the distribution of 'crop' and 'weed' classes.\n",
        "*   Visualizing the distributions of bounding box 'width' and 'height'.\n",
        "*   Calculating and visualizing the distribution of bounding box aspect ratios.\n",
        "*   Displaying a few sample images with their corresponding bounding box annotations to visually inspect the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d83defe"
      },
      "source": [
        "## Analyze Class Distribution\n",
        "\n",
        "### Subtask:\n",
        "Examine the distribution of 'crop' and 'weed' classes within the annotations DataFrame to understand the balance between the two categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59da8b60"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand the distribution of 'crop' and 'weed' classes, I will calculate the value counts of the 'class_id' column in the `annotations_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f69d9cd5"
      },
      "source": [
        "class_distribution = annotations_df['class_id'].value_counts()\n",
        "print(\"Class distribution (0: crop, 1: weed):\")\n",
        "print(class_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6362fa57"
      },
      "source": [
        "**Reasoning**:\n",
        "To visually represent the distribution of 'crop' and 'weed' classes, I will create a bar plot from the `class_distribution` Series. This will provide a clear understanding of the balance between the two categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4e36782"
      },
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "class_distribution.plot(kind='bar', color=['lightgreen', 'red'])\n",
        "plt.title('Distribution of Crop and Weed Classes')\n",
        "plt.xlabel('Class ID (0: Crop, 1: Weed)')\n",
        "plt.ylabel('Number of Annotations')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a39d7018"
      },
      "source": [
        "## Visualize Bounding Box Dimensions\n",
        "\n",
        "### Subtask:\n",
        "Plot histograms or descriptive statistics for 'width' and 'height' of the bounding boxes to understand the typical sizes and variations of detected objects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78a270be"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand the distribution of bounding box widths, I will plot a histogram of the 'width' column from the annotations DataFrame, adding appropriate labels and a title for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "917aab50"
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(annotations_df['width'], bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Bounding Box Widths')\n",
        "plt.xlabel('Width')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04a8155f"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand the distribution of bounding box heights, I will plot a histogram of the 'height' column from the annotations DataFrame, adding appropriate labels and a title for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d88a4de"
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(annotations_df['height'], bins=30, color='lightcoral', edgecolor='black')\n",
        "plt.title('Distribution of Bounding Box Heights')\n",
        "plt.xlabel('Height')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8b4ac1"
      },
      "source": [
        "**Reasoning**:\n",
        "To analyze the aspect ratio distribution, I will first calculate the aspect ratio (width / height) for each bounding box and add it as a new column to the annotations DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91f0305a"
      },
      "source": [
        "annotations_df['aspect_ratio'] = annotations_df['width'] / annotations_df['height']\n",
        "\n",
        "print(\"First 5 rows of the annotations DataFrame with aspect_ratio:\")\n",
        "print(annotations_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772726db"
      },
      "source": [
        "**Reasoning**:\n",
        "To visualize the distribution of aspect ratios, I will plot a histogram of the 'aspect_ratio' column from the annotations DataFrame, adding appropriate labels and a title for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "241e54e2"
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(annotations_df['aspect_ratio'], bins=30, color='lightgreen', edgecolor='black')\n",
        "plt.title('Distribution of Bounding Box Aspect Ratios')\n",
        "plt.xlabel('Aspect Ratio (Width / Height)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "516abd99"
      },
      "source": [
        "## Display Sample Images with Bounding Box Annotations\n",
        "\n",
        "### Subtask:\n",
        "Display a few sample images from the dataset with their corresponding bounding box annotations drawn on them. This visualization will help in understanding the quality and nature of the annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdf8905f"
      },
      "source": [
        "**Reasoning**:\n",
        "To display sample images with bounding box annotations, I need to identify the paths to image files and their corresponding bounding box data. First, I will collect all unique image filenames from the 'image_name' column of the `annotations_df` to ensure I pick images that have associated annotations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4336295c"
      },
      "source": [
        "unique_image_names = annotations_df['image_name'].unique()\n",
        "print(f\"Found {len(unique_image_names)} unique images with annotations.\")\n",
        "print(\"First 5 unique image names:\")\n",
        "print(unique_image_names[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cd5c899"
      },
      "source": [
        "**Reasoning**:\n",
        "To display sample images with bounding boxes, I need a helper function to load an image and draw the bounding boxes on it. This function will convert the normalized YOLO format bounding box coordinates to pixel coordinates suitable for drawing on the image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2704bc47"
      },
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_image_with_boxes(image_path, annotations, class_names):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    img_width, img_height = image.size\n",
        "\n",
        "    for idx, row in annotations.iterrows():\n",
        "        class_id = int(row['class_id'])\n",
        "        x_center, y_center, width, height = row['x_center'], row['y_center'], row['width'], row['height']\n",
        "\n",
        "        # Convert YOLO format (normalized center_x, center_y, width, height) to pixel coordinates (x_min, y_min, x_max, y_max)\n",
        "        x_min = int((x_center - width / 2) * img_width)\n",
        "        y_min = int((y_center - height / 2) * img_height)\n",
        "        x_max = int((x_center + width / 2) * img_width)\n",
        "        y_max = int((y_center + height / 2) * img_height)\n",
        "\n",
        "        color = 'red' if class_id == 1 else 'green' # Red for weed, Green for crop\n",
        "        draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=3)\n",
        "\n",
        "        # Add class label\n",
        "        class_name = class_names.get(class_id, f'Class {class_id}')\n",
        "        draw.text((x_min + 5, y_min + 5), class_name, fill=color)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Image: {os.path.basename(image_path)}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"plot_image_with_boxes function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98727957"
      },
      "source": [
        "**Reasoning**:\n",
        "To display sample images with bounding box annotations, I need to create a dictionary mapping class IDs to class names (e.g., 0: 'crop', 1: 'weed'). This mapping will be used by the `plot_image_with_boxes` function to label the bounding boxes correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cda7d491"
      },
      "source": [
        "class_names = {0: 'crop', 1: 'weed'}\n",
        "print(f\"Class name mapping: {class_names}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "835a0d7f"
      },
      "source": [
        "**Reasoning**:\n",
        "To visually inspect the data, I will display a few sample images with their bounding box annotations. I'll select a small number of unique images to plot using the `plot_image_with_boxes` function, iterating through them and filtering their annotations from the `annotations_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "177b226f"
      },
      "source": [
        "num_samples = 3 # Number of sample images to display\n",
        "\n",
        "for i, image_name in enumerate(unique_image_names[:num_samples]):\n",
        "    image_path = os.path.join(data_dir, image_name)\n",
        "    image_annotations = annotations_df[annotations_df['image_name'] == image_name]\n",
        "\n",
        "    if os.path.exists(image_path):\n",
        "        print(f\"Displaying sample image {i+1}/{num_samples}: {image_name}\")\n",
        "        plot_image_with_boxes(image_path, image_annotations, class_names)\n",
        "    else:\n",
        "        print(f\"Image file not found: {image_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e299eb69"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset contains more 'crop' annotations than 'weed' annotations, with **1212** instances of 'crop' (Class ID 0) and **860** instances of 'weed' (Class ID 1).\n",
        "*   The distributions of bounding box widths and heights were visualized using histograms, showing the typical sizes and variations of detected objects.\n",
        "*   Bounding box aspect ratios (width / height) were calculated and their distribution was visualized, providing insight into the shape characteristics of the annotated objects.\n",
        "*   Several sample images were successfully displayed with their corresponding bounding box annotations, allowing for a visual inspection of the data and confirming the correct mapping of 'crop' and 'weed' labels.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The class imbalance between 'crop' and 'weed' (1212 vs. 860) suggests that data augmentation or specific sampling strategies might be beneficial during model training to prevent bias towards the 'crop' class.\n",
        "*   Further statistical analysis of bounding box dimensions and aspect ratios (e.g., mean, median, standard deviation, and outliers) could inform anchor box design for object detection models, potentially improving model performance.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}